{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['Время получения', 'Время прочтения', 'Время отправки ответа']\n",
    "email_dataset = pd.read_csv('samples/modified_email_dataset.csv', sep=';', encoding='utf-8', parse_dates=date_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix datetime format of columns with adding seconds where values is not nan\n",
    "# NOT IMPLEMENT ANY MORE!\n",
    "for col in date_cols:\n",
    "    # get indexes of not nan values\n",
    "    not_nan_indexes = email_dataset[col].notna()\n",
    "    # add seconds to values if length of value is 16\n",
    "    email_dataset.loc[not_nan_indexes, col] = email_dataset.loc[not_nan_indexes, col].apply(\n",
    "        lambda x: x + ':00' if len(x) == 16 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  parse columns to datetime\n",
    "for col in date_cols:\n",
    "    email_dataset[col] = pd.to_datetime(email_dataset[col], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required packages\n",
    "!pip install torch transformers sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete conflict versions of numpy\n",
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "from enum import Enum\n",
    "\n",
    "emotion_tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment-rurewiews')\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment-rurewiews', return_dict=True)\n",
    "\n",
    "class EmotionDetection():\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    class Emotion(Enum):\n",
    "        NEUTRAL = 0\n",
    "        POSITIVE = 1\n",
    "        NEGATIVE = 2\n",
    "\n",
    "    def predict(self, text) -> Emotion:\n",
    "        inputs = self.tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "        outputs = self.model(**inputs)\n",
    "        predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        predicted = torch.argmax(predicted, dim=1).numpy()\n",
    "        return EmotionDetection.Emotion(predicted[0])\n",
    "\n",
    "# 0: NEUTRAL\n",
    "# 1: POSITIVE\n",
    "# 2: NEGATIVE\n",
    "model_emotions = EmotionDetection(emotion_tokenizer, emotion_model)\n",
    "# example:\n",
    "# e\n",
    "# emotion_model.predict(\"Да отвали ты от меня\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emotions.predict(\"Да отвали ты от меня\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unanswered questions model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re\n",
    "counter_model = SentenceTransformer('sentence-transformers/use-cmlm-multilingual')\n",
    "\n",
    "\n",
    "class UnansweredCounterBase():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def extract_questions(self, text):\n",
    "        return [t.strip() for t in re.findall(r'[^.!?]*\\?', text)]\n",
    "\n",
    "    def extract_sentences(self, text):\n",
    "        return [t.strip() for t in re.findall(r'[^.!?]+[.!?]', text)]\n",
    "\n",
    "    def prepare_context(self, context):\n",
    "        return self.extract_questions(context)\n",
    "\n",
    "    def prepare_answer(self, answer):\n",
    "        return self.extract_sentences(answer)\n",
    "\n",
    "context = \"\"\"Добрый день, Илья!\n",
    "\n",
    "Надеюсь, этот день проходит у вас продуктивно. Я пишу, чтобы уточнить несколько важных моментов по нашему текущему проекту:\n",
    "\n",
    "Можете ли вы обновить меня относительно текущего статуса проекта? Какие основные этапы уже завершены?\n",
    "\n",
    "Как обстоят дела в команде? Есть ли какие-то сложности или препятствия, о которых нам следует знать?\n",
    "\n",
    "Соблюдаются ли запланированные сроки? Есть ли риск задержек в достижении ключевых вех проекта?\n",
    "\n",
    "Буду признателен за оперативный ответ, так как это поможет нам в планировании следующих шагов.\n",
    "\n",
    "С уважением,\n",
    "Егор\n",
    "\"\"\"\n",
    "answer = \"\"\"Добрый день, Егор!\n",
    "\n",
    "Спасибо за ваше обращение. Я рад сообщить вам о последних достижениях нашего проекта:\n",
    "\n",
    "На данный момент мы успешно завершили первые два этапа проекта, включая исследовательскую фазу и начальную разработку. В настоящее время мы активно работаем над следующим этапом, который ориентирован на разработку основных функциональностей.\n",
    "\n",
    "Что касается команды, все идет хорошо. Несмотря на некоторые начальные трудности с координацией задач, на данный момент все проблемы решены, и команда работает слаженно.\n",
    "\n",
    "Если у вас возникнут дополнительные вопросы, не стесняйтесь обращаться.\n",
    "\n",
    "С уважением,\n",
    "Илья\"\"\"\n",
    "\n",
    "class UnansweredCounter():\n",
    "    def __init__(self, context: str, answer: str, model):\n",
    "        self.unanswered_counter = model\n",
    "        self.context = context\n",
    "        self.answer = answer\n",
    "\n",
    "    def count(self) -> int:\n",
    "        context = self.unanswered_counter.prepare_context(self.context)\n",
    "        answer = self.unanswered_counter.prepare_answer(self.answer)\n",
    "        num_questions = len(context)\n",
    "        count = 0\n",
    "        for question in context:\n",
    "            embedding_1 = self.unanswered_counter.model.encode(question, convert_to_tensor=True)\n",
    "            for sentence in answer:\n",
    "                embedding_2 = self.unanswered_counter.model.encode(sentence, convert_to_tensor=True)\n",
    "                score = util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "                if score >= 0.27:\n",
    "                    count += 1\n",
    "                    break\n",
    "        return num_questions - count\n",
    "\n",
    "\n",
    "\n",
    "# unanswered_counter = UnansweredCounterBase(counter_model)\n",
    "# context = unanswered_counter.prepare_context(context)\n",
    "# answer = unanswered_counter.prepare_answer(answer)\n",
    "\n",
    "# count = 0\n",
    "# for question in context:\n",
    "#     embedding_1 = unanswered_counter.model.encode(question, convert_to_tensor=True)\n",
    "#     for sentence in answer:\n",
    "#         embedding_2 = unanswered_counter.model.encode(sentence, convert_to_tensor=True)\n",
    "#         score = util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "#         if score >= 0.27:\n",
    "#           print(\"----------------------------------------------------------------------------\")\n",
    "#           print(f\"Context: {question}\")\n",
    "#           print(f\"Answer: {sentence}\")\n",
    "#           print(f\"Similarity: {score}\")\n",
    "#           print(\"----------------------------------------------------------------------------\")\n",
    "#           count += 1\n",
    "#           break\n",
    "# print(count)\n",
    "base_counter_model = UnansweredCounterBase(counter_model)\n",
    "unAnsweredCounter = UnansweredCounter(context, answer, base_counter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unAnsweredCounter.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxcicity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ToxicLanguageIndetifier(nn.Module):\n",
    "    def __init__(self, model_name = \"s-nlp/russian_toxicity_classifier\"):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    def toxic_probality(self, text):\n",
    "        text_toxicity = self.tokenizer(text, return_tensors='pt')\n",
    "        preds = self.model(**text_toxicity).logits\n",
    "        return ['neutral', 'toxic'][preds.softmax(dim=-1).argmax(dim=-1)]\n",
    "\n",
    "toxic_model = ToxicLanguageIndetifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_model.toxic_probality(\"Сбер - контора пидорасов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priority model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioriotyModel(nn.Module):\n",
    "    def __init__(self, model_name=\"fathyshalaby/emailclassifier\", classes=['высокая срочность', 'средняя срочность', 'не срочно']):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.classes = classes\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.model.classifier = nn.Linear(in_features=768, out_features=len(classes), bias=True)\n",
    "\n",
    "    def get_priority(self, text: str):\n",
    "\n",
    "        tokenized_text = self.tokenizer(text, return_tensors='pt')\n",
    "        preds = self.model(**tokenized_text).logits\n",
    "        return self.classes[preds.softmax(dim=-1).argmax(dim=-1)]\n",
    "\n",
    "priority_model = PrioriotyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_model.get_priority(\"Добрый день, возник вопрос по системе учета переработок. Какие шаги нужно предпринять, чтобы получить информацию по своему рабочему времени?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_salary():\n",
    "    salary_range = list(range(20000, 100001, 5000))\n",
    "    weights = [i for i in range(1, len(salary_range) + 1)]\n",
    "    weights.reverse()\n",
    "    print(weights)\n",
    "    return random.choices(salary_range, weights=weights)[0]\n",
    "\n",
    "# 8\n",
    "def number_of_answered_emails(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> int:\n",
    "    # return count of answered emails\n",
    "    return df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date) & (df['Время отправки ответа'].notna())].shape[0]\n",
    "\n",
    "# 1\n",
    "def number_of_sent_emails(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> int:\n",
    "    # return count of sent emails by user_email between start_date and end_date\n",
    "    sender_count =  df[(df['Почтовый адрес отправителя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date)].shape[0]\n",
    "    answer_count = number_of_answered_emails(user_email, start_date, end_date, df)\n",
    "    return sender_count + answer_count\n",
    "\n",
    "# 2\n",
    "def number_of_received_emails(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> int:\n",
    "    # return count of received emails by user_email between start_date and end_date\n",
    "    return df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date)].shape[0]\n",
    "\n",
    "# 3\n",
    "def mean_number_of_recipients_in_one_email_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> float:\n",
    "    # generate random number from 1 to 5\n",
    "    return np.random.randint(1, 5)\n",
    "\n",
    "# 6\n",
    "def number_of_emails_read_after_x_minutes(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame, minutes: int = 1) -> int:\n",
    "    # return count of emails read after x minutes after receiving\n",
    "    return df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date) & (df['Время прочтения'] - df['Время получения'] >= pd.Timedelta(minutes=minutes))].shape[0]\n",
    "\n",
    "# 7\n",
    "def mean_number_of_days_between_receiving_emails_and_read(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> int:\n",
    "    # return mean number of days between receiving emails and read\n",
    "    data = df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date) & (df['Время прочтения'].notna())]\n",
    "    return data['Время прочтения'].sub(data['Время получения']).mean().days\n",
    "\n",
    "# 9\n",
    "def mean_length_of_user_emails(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> float:\n",
    "    # return mean length of user emails text. Both sent and answered\n",
    "    mean_length_sent = df[(df['Почтовый адрес отправителя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date)]['Текст письма'].str.len().mean()\n",
    "    mean_length_answered = df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date) & (df['Время отправки ответа'].notna())]['Текст ответа'].str.len().mean()\n",
    "    return (mean_length_sent + mean_length_answered) / 2\n",
    "\n",
    "# 10\n",
    "def number_of_sent_emails_outside_of_working_hours(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> int:\n",
    "    working_hours = (10, 18)\n",
    "    # return count of sent emails outside of working hours\n",
    "    sent_emails = df[(df['Почтовый адрес отправителя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date)]\n",
    "    answered_emails = df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date) & (df['Время отправки ответа'].notna())]\n",
    "    # apply working hours filter\n",
    "    sent_emails = sent_emails[(sent_emails['Время получения'].dt.hour < working_hours[0]) | (sent_emails['Время получения'].dt.hour > working_hours[1])]\n",
    "    answered_emails = answered_emails[(answered_emails['Время отправки ответа'].dt.hour < working_hours[0]) | (answered_emails['Время отправки ответа'].dt.hour > working_hours[1])]\n",
    "    return sent_emails.shape[0] + answered_emails.shape[0]\n",
    "\n",
    "\n",
    "# 11\n",
    "def received_and_sent_emails_proportion_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> float:\n",
    "    return number_of_received_emails(user_email, start_date, end_date, df) / number_of_sent_emails(user_email, start_date, end_date, df)\n",
    "\n",
    "# 13\n",
    "def number_of_not_answered_questions_in_email(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> float:\n",
    "    # return count of not answered questions in email using ML\n",
    "    total_emails = number_of_answered_emails(user_email, start_date, end_date, df)\n",
    "    count = 0\n",
    "    for index, row in df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date) & (df['Время отправки ответа'].notna())].iterrows():\n",
    "        unanswered_counter = UnansweredCounter(row['Текст письма'], row['Текст ответа'], base_counter_model)\n",
    "        count += unanswered_counter.count()\n",
    "    return count / total_emails\n",
    "\n",
    "# 14\n",
    "def salary_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> int:\n",
    "    return random_salary()\n",
    "\n",
    "# 15\n",
    "def mean_working_hours_per_day_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> float:\n",
    "    # return random number from 6 to 12\n",
    "    return np.random.randint(6, 12)\n",
    "\n",
    "def reply_delay_for_prioritised_emails(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> dict:\n",
    "    # return dict with count of emails with different priority and mean delay for each priority\n",
    "    # return random dict\n",
    "    return {\n",
    "        'высокая срочность': np.random.randint(5, 180),\n",
    "        'средняя срочность': np.random.randint(20, 300),\n",
    "        'не срочно': np.random.randint(60, 480)\n",
    "    }\n",
    "\n",
    "# TODO define the returning type\n",
    "def emotions_in_sent_emails_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> str:\n",
    "    # return main emotion for each sent and answered email\n",
    "    total_eamils = number_of_sent_emails(user_email, start_date, end_date, df)\n",
    "    emotion_temperature = 0\n",
    "    for index, row in df[(df['Почтовый адрес отправителя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date)].iterrows():\n",
    "        value = model_emotions.predict(row['Текст письма']).value\n",
    "        if value == 2:\n",
    "            value = -1\n",
    "        emotion_temperature += value\n",
    "    for index, row in df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date) & (df['Время отправки ответа'].notna())].iterrows():\n",
    "        value = model_emotions.predict(row['Текст ответа']).value\n",
    "        if value == 2:\n",
    "            value = -1\n",
    "        emotion_temperature += value\n",
    "    mean_temperature = emotion_temperature / total_eamils\n",
    "    # if mean_temperature is close to 0 then return neutral. If mean_temperature is close to 1 then return positive. If mean_temperature is close to -1 then return negative\n",
    "    if mean_temperature > 0.3:\n",
    "        return 'POSITIVE'\n",
    "    elif mean_temperature < -0.3:\n",
    "        return 'NEGATIVE'\n",
    "    else:\n",
    "        return 'NEUTRAL'\n",
    "\n",
    "# TODO define the returning type\n",
    "def emotions_in_received_emails_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> int:\n",
    "    # return main emotion for each received email\n",
    "    total_emails = number_of_received_emails(user_email, start_date, end_date, df)\n",
    "    emotion_temperature = 0\n",
    "    for index, row in df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date)].iterrows():\n",
    "        value = model_emotions.predict(row['Текст письма']).value\n",
    "        if value == 2:\n",
    "            value = -1\n",
    "        emotion_temperature += value\n",
    "    mean_temperature = emotion_temperature / total_emails\n",
    "    # if mean_temperature is close to 0 then return neutral. If mean_temperature is close to 1 then return positive. If mean_temperature is close to -1 then return negative\n",
    "    if mean_temperature > 0.3:\n",
    "        return 'POSITIVE'\n",
    "    elif mean_temperature < -0.3:\n",
    "        return 'NEGATIVE'\n",
    "    else:\n",
    "        return 'NEUTRAL'\n",
    "\n",
    "def toxcity_in_sent_emails_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> float:\n",
    "    # return mean toxicity of each sent and answered email\n",
    "    total_emails = number_of_sent_emails(user_email, start_date, end_date, df)\n",
    "    toxicity_counter = 0\n",
    "    for index, row in df[(df['Почтовый адрес отправителя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date)].iterrows():\n",
    "        toxicity_counter += toxic_model.toxic_probality(row['Текст письма']) == 'toxic'\n",
    "    for index, row in df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date) & (df['Время отправки ответа'].notna())].iterrows():\n",
    "        toxicity_counter += toxic_model.toxic_probality(row['Текст ответа']) == 'toxic'\n",
    "    toxic_level = toxicity_counter / total_emails\n",
    "    if toxic_level > 0.3:\n",
    "        return 'HIGH'\n",
    "    elif toxic_level < 0.1:\n",
    "        return 'LOW'\n",
    "    else:\n",
    "        return 'MEDIUM'\n",
    "\n",
    "def toxcity_in_received_emails_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> float:\n",
    "    # return mean toxicity of each received email\n",
    "    total_emails = number_of_received_emails(user_email, start_date, end_date, df)\n",
    "    toxicity_counter = 0\n",
    "    for index, row in df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date)].iterrows():\n",
    "        toxicity_counter += toxic_model.toxic_probality(row['Текст письма']) == 'toxic'\n",
    "    toxic_level = toxicity_counter / total_emails\n",
    "    if toxic_level > 0.3:\n",
    "        return 'HIGH'\n",
    "    elif toxic_level < 0.1:\n",
    "        return 'LOW'\n",
    "    else:\n",
    "        return 'MEDIUM'\n",
    "\n",
    "# TODO define the returning type\n",
    "def mean_answering_time_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> float:\n",
    "    # return mean answering time for user\n",
    "    data = df[(df['Почтовый адрес получателя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date) & (df['Время отправки ответа'].notna())]\n",
    "    return data['Время отправки ответа'].sub(data['Время получения']).mean().seconds / 60\n",
    "def number_of_passed_corporative_tests_or_courses_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> int:\n",
    "    # return count of passed corporative tests or courses for user. Return random number from 0 to 3\n",
    "    return np.random.randint(0, 3)\n",
    "\n",
    "def number_of_unique_recipients_of_emails_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> int:\n",
    "    # return count of unique recipients of emails for user\n",
    "    return df[(df['Почтовый адрес отправителя'] == user_email) & (df['Время получения'] >= start_date) & (df['Время получения'] <= end_date)]['Почтовый адрес получателя'].nunique()\n",
    "\n",
    "def number_of_unique_departments_in_emails_for_user(user_email: str, start_date: datetime, end_date: datetime, df: pd.DataFrame) -> int:\n",
    "    # return count of unique departments in emails for user. Return random number from 1 to 5\n",
    "    return np.random.randint(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_answering_time_for_user('49@company.com', datetime(2020, 1, 1), datetime(2030, 1, 1), email_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_dataset[email_dataset['Почтовый адрес получателя'] == '49@company.com' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix dataset on sent emails\n",
    "# if there is no text of reply email, then set answer time end theme of email to nan\n",
    "email_dataset.loc[(email_dataset['Текст ответа'].isna()), 'Время отправки ответа'] = pd.NaT\n",
    "email_dataset.loc[(email_dataset['Текст ответа'].isna()), 'Тема ответа'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_dataset.to_csv('export/final_email_dataset.csv', sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lowest date and highest date from dataset\n",
    "lowest_date = email_dataset['Время получения'].min()\n",
    "highest_date = email_dataset['Время получения'].max()\n",
    "print(f'low: {lowest_date}; high: {highest_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "def get_same_weekday_date(input_date: datetime) -> datetime:\n",
    "    target_weekday = input_date.weekday()\n",
    "    start_date = datetime(2023, 12, 4)\n",
    "    end_date = datetime(2023, 12, 10)\n",
    "\n",
    "    # Find the first date with the same weekday as the input date\n",
    "    current_date = start_date\n",
    "    while current_date.weekday() != target_weekday:\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # Check if the found date is within the desired range\n",
    "    if current_date < start_date:\n",
    "        current_date += timedelta(days=7)\n",
    "    elif current_date > end_date:\n",
    "        current_date -= timedelta(days=7)\n",
    "\n",
    "    # Save the time of the input_date to the output datetime\n",
    "    current_date = current_date.replace(hour=input_date.hour, minute=input_date.minute, second=input_date.second, microsecond=input_date.microsecond)\n",
    "\n",
    "    return current_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all dates in dataset with same weekday dates from function above. Only non nan values\n",
    "for col in date_cols:\n",
    "    not_nan_indexes = email_dataset[col].notna()\n",
    "    email_dataset.loc[not_nan_indexes, col] = email_dataset.loc[not_nan_indexes, col].apply(get_same_weekday_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_dataset.to_csv('export/modified_email_dataset.csv', sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_salary():\n",
    "    salary_range = list(range(20000, 100001, 5000))\n",
    "    weights = [i for i in range(1, len(salary_range) + 1)]\n",
    "    weights.reverse()\n",
    "    print(weights)\n",
    "    return random.choices(salary_range, weights=weights)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary = random_salary()\n",
    "print(salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "# generate metrics for each user\n",
    "# get all unique users from dataset from column 'Почтовый адрес получателя' and 'Почтовый адрес отправителя'\n",
    "unique_users = set(email_dataset['Почтовый адрес получателя'].unique().tolist() + email_dataset['Почтовый адрес отправителя'].unique().tolist())\n",
    "\n",
    "# set delay threshold in minutes\n",
    "delay_trshld = 60\n",
    "# generate metrics for each user\n",
    "metrics_dataset = pd.DataFrame(columns=['Почтовый адрес',\n",
    "                                        'Колличество ответов',\n",
    "                                        'Количество отправленных писем',\n",
    "                                        'Количество полученных писем',\n",
    "                                        'Среднее количество получателей в письме',\n",
    "                                        f'Количество писем, прочитанных через {delay_trshld} минут после получения',\n",
    "                                        'Среднее количество дней между получением и прочтением письма',\n",
    "                                        'Количество писем, отправленных в нерабочее время',\n",
    "                                        'Соотношение полученных и отправленных писем',\n",
    "                                        'Количество неотвеченных вопросов в письмах',\n",
    "                                        'Средняя длина письма',\n",
    "                                        'Среднее время ответа на письмо',\n",
    "                                        'Количество пройденных корпоративных тестов и курсов',\n",
    "                                        'Количество уникальных получателей писем',\n",
    "                                        'Количество уникальных отделов в письмах',\n",
    "                                        'Средняя токсичность отправленных писем',\n",
    "                                        'Средняя токсичность полученных писем',\n",
    "                                        'Средняя эмоциональность отправленных писем',\n",
    "                                        'Средняя эмоциональность полученных писем',\n",
    "                                        'Зарплата'])\n",
    "for user in tqdm.tqdm(unique_users):\n",
    "    data = {\n",
    "        'Почтовый адрес': user,\n",
    "        'Колличество ответов': number_of_answered_emails(user, lowest_date, highest_date, email_dataset),\n",
    "        'Количество отправленных писем': number_of_sent_emails(user, lowest_date, highest_date, email_dataset),\n",
    "        'Количество полученных писем': number_of_received_emails(user, lowest_date, highest_date, email_dataset),\n",
    "        'Среднее количество получателей в письме': mean_number_of_recipients_in_one_email_for_user(user, lowest_date, highest_date, email_dataset),\n",
    "        f'Количество писем, прочитанных через {delay_trshld} минут после получения': number_of_emails_read_after_x_minutes(user, lowest_date, highest_date, email_dataset, delay_trshld),\n",
    "        'Среднее количество дней между получением и прочтением письма': mean_number_of_days_between_receiving_emails_and_read(user, lowest_date, highest_date, email_dataset),\n",
    "        'Количество писем, отправленных в нерабочее время': number_of_sent_emails_outside_of_working_hours(user, lowest_date, highest_date, email_dataset),\n",
    "        'Соотношение полученных и отправленных писем': received_and_sent_emails_proportion_for_user(user, lowest_date, highest_date, email_dataset),\n",
    "        'Количество неотвеченных вопросов в письмах': number_of_not_answered_questions_in_email(user, lowest_date, highest_date, email_dataset),\n",
    "        'Средняя длина письма': mean_length_of_user_emails(user, lowest_date, highest_date, email_dataset),\n",
    "        'Среднее время ответа на письмо': mean_answering_time_for_user(user, lowest_date, highest_date, email_dataset),\n",
    "        'Количество пройденных корпоративных тестов и курсов': number_of_passed_corporative_tests_or_courses_for_user(user, lowest_date, highest_date, email_dataset),\n",
    "        'Количество уникальных получателей писем': number_of_unique_recipients_of_emails_for_user(user, lowest_date, highest_date, email_dataset),\n",
    "        'Количество уникальных отделов в письмах': number_of_unique_departments_in_emails_for_user(user, lowest_date, highest_date, email_dataset),\n",
    "        'Средняя токсичность отправленных писем': toxcity_in_sent_emails_for_user(user, lowest_date, highest_date, email_dataset),\n",
    "        'Средняя токсичность полученных писем': toxcity_in_received_emails_for_user(user, lowest_date, highest_date, email_dataset),\n",
    "        'Средняя эмоциональность отправленных писем': emotions_in_sent_emails_for_user(user, lowest_date, highest_date, email_dataset),\n",
    "        'Средняя эмоциональность полученных писем': emotions_in_received_emails_for_user(user, lowest_date, highest_date, email_dataset),\n",
    "        'Зарплата': salary_for_user(user, lowest_date, highest_date, email_dataset)\n",
    "    }\n",
    "    metrics_dataset = pd.concat([metrics_dataset, pd.DataFrame([data])], ignore_index=True)\n",
    "\n",
    "metrics_dataset.to_csv('export/metrics_dataset.csv', sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace fixed columns 'Среднее количество дней между получением и прочтением письма' and 'Среднее время ответа на письмо' with new values\n",
    "metrics_dataset['Среднее количество дней между получением и прочтением письма'] = metrics_dataset['Почтовый адрес'].apply(lambda x: mean_number_of_days_between_receiving_emails_and_read(x, lowest_date, highest_date, email_dataset))\n",
    "metrics_dataset['Среднее время ответа на письмо'] = metrics_dataset['Почтовый адрес'].apply(lambda x: mean_answering_time_for_user(x, lowest_date, highest_date, email_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new columns for reply_delay_for_prioritised_emails. Each column is a key of dict\n",
    "for user in tqdm.tqdm(unique_users):\n",
    "    data = reply_delay_for_prioritised_emails(user, lowest_date, highest_date, email_dataset)\n",
    "    # add new columns for each key in dict\n",
    "    for key in data.keys():\n",
    "        metrics_dataset.loc[metrics_dataset['Почтовый адрес'] == user, key] = data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dataset.to_csv('export/metrics_dataset.csv', sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix metrics dataset of column 'Среднее количество дней между получением и прочтением письма' with multiplying by -1\n",
    "metrics_dataset['Среднее количество дней между получением и прочтением письма'] = metrics_dataset['Среднее количество дней между получением и прочтением письма'].apply(lambda x: x * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dataset.to_csv('export/metrics_dataset.csv', sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_next_week_dates(date_str):\n",
    "    # Convert the input string to a datetime object\n",
    "    given_date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "\n",
    "    # Find out the day of the week (0=Monday, 6=Sunday)\n",
    "    day_of_week = given_date.weekday()\n",
    "\n",
    "    # Calculate the start of the next week (next Monday)\n",
    "    # If the given day is Monday, we need to add 7 days to get to the next Monday\n",
    "    days_till_next_monday = 7 - day_of_week\n",
    "    start_of_next_week = given_date + timedelta(days=days_till_next_monday)\n",
    "\n",
    "    # End of the next week (next Sunday) is 6 days after the start of the week\n",
    "    end_of_next_week = start_of_next_week + timedelta(days=6)\n",
    "\n",
    "    # Return the dates as strings\n",
    "    return start_of_next_week, end_of_next_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
